{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API 4-3: REST APIs\n",
    "\n",
    "Open AI, LLM API's, OAUTH2 Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open AI API\n",
    "\n",
    "\n",
    "Artifical Intelligence has become more accessible thanks to REST API's. It is not possible to run most of these models on your local machine due to the computational power required. Companies like Open AI, Anthropic, and Perplexity have made it possible to access their models through Web API's. This has opened up a new world of possibilities for developers to build applications that can understand and generate human-like text, create art / music, and solve puzzles.\n",
    "\n",
    "In this course will use Open AI's API to demonstrate some of these capabilities. \n",
    "\n",
    "We will use the Open AI API in the IoT Portal. This will allow you to use the API without having to pay for it.\n",
    "\n",
    "\n",
    "## Text Generation\n",
    "\n",
    "- Text generation is the process of generating text using a model that has been trained on a large corpus of text. We provide the model a **text prompt** consisting of a question, insructions, examples, or both. The model then generates a response based on the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an AI, so I can do a wide range of tasks. Here are some examples:\n",
      "\n",
      "**Conversational Dialogue**: I can have natural-sounding conversations with you! Ask me a question, tell me a joke, or just chat about something that interests you.\n",
      "\n",
      "**Answering Questions**: I've been trained on a massive dataset and can provide answers to questions on various topics, including science, history, technology, literature, and more.\n",
      "\n",
      "**Generating Text**: I can create text based on a prompt, topic, or style. This can be useful for writing articles, creating content, or even composing emails.\n",
      "\n",
      "**Summarizing Content**: If you have a long piece of text and want me to summarize it for you, I can do that too! Just give me the text and let me know how concise you'd like the summary to be.\n",
      "\n",
      "**Translation**: I can translate text from one language to another. Currently, I support translations in dozens of languages, including popular languages like Spanish, French, German, Chinese, Japanese, and many more.\n",
      "\n",
      "**Text Analysis**: I can analyze text data, such as sentiment analysis (determining whether text is positive, negative, or neutral), entity recognition (identifying people, places, and things mentioned in the text), and topic modeling (identifying themes or topics within a piece of text).\n",
      "\n",
      "**Creative Writing**: If you want me to generate creative writing, such as poetry or short stories, I can do that too! Just give me some prompts and let me know what kind of tone you're looking for.\n",
      "\n",
      "**Jokes and Humor**: I can share jokes with you or even generate humorously related text based on a topic or theme.\n",
      "\n",
      "**Generating Code**: If you need help with coding, I can provide suggestions or even generate code snippets in certain programming languages (like Python, Java, JavaScript, etc.).\n",
      "\n",
      "These are just a few examples of what I can do. Do you have a specific task in mind?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = \"ec25dc1e1297cfba51838bd3\"\n",
    "uri = \"https://cent.ischool-iot.net/api/genai/generate\"\n",
    "prompt = \"What are your capabilities?\"\n",
    "\n",
    "data = { \"query\": prompt }\n",
    "response = requests.post(uri, data=data, headers={\"x-api-key\": api_key})\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Going On Here?\n",
    "\n",
    "Open AI is a Large Language Model. It is capable of generating text based on a prompt. While it might appear smart or intelligent, it is important to remember that it is just codethat has been trained on a huge large corpus of text. The model does not have any understanding of the world or the text it generates, its just generating output based on the input and the text is was trained on!\n",
    "\n",
    "\n",
    "## Large Language Model Capabilities\n",
    "\n",
    "- **Question Answering**: Ask a question and the model will generate an answer (provided its in the corpus).\n",
    "- **Text Completion**: Provide a sentence and the model will complete it.\n",
    "- **Text Summarization**: Provide a prompt and the model will summarize the text.\n",
    "- **Text Classification**: Provide a prompt and the model will classify the text.\n",
    "- **Text Translation**: Provide a prompt and the model will translate the text.\n",
    "- **Text Sentiment Analysis**: Provide a prompt and the model will analyze the sentiment of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION-ANSWERING: What is the capital of France? ==> The capital of France is Paris.\n",
      "\n",
      "\n",
      "TEXT-COMPLETION: Finish this sentence: 'Once upon a time _____' ==> ...in a land far, far away, there lived a beautiful princess named Sophia who had hair as golden as the sun and a smile that could light up the entire kingdom.\n",
      "\n",
      "\n",
      "TEXT-SUMMARIZATION: Explain this: 'The best revenge is to be unlike him who performed the injury.' ==> A timeless wisdom!\n",
      "\n",
      "This quote, often attributed to Marcus Aurelius, a Roman emperor and philosopher, suggests that the most effective way to respond to someone who has wronged or hurt you is not to seek direct revenge or try to harm them in return. Instead, it advises you to focus on becoming a better version of yourself.\n",
      "\n",
      "In other words, the quote implies that by changing your own behavior, thoughts, and character for the better, you are, in effect, rendering the person who wronged you powerless to affect you further. You're essentially saying, \"I'm not going to let your actions define me or dictate my response. I'm going to rise above it and become a stronger, wiser, and more compassionate person.\"\n",
      "\n",
      "This approach has several benefits:\n",
      "\n",
      "1. **It lets go of negative emotions**: By focusing on personal growth, you release the need for revenge or retaliation, which can be draining and consume your thoughts.\n",
      "2. **It sets boundaries**: You're establishing a clear boundary by choosing not to engage in a cycle of negativity or harm.\n",
      "3. **It empowers you**: By taking control of your own transformation, you're gaining confidence, self-awareness, and personal power.\n",
      "4. **It shows no weakness**: Your response is perceived as strong and rational, rather than weak or vengeful.\n",
      "\n",
      "In summary, the quote encourages you to focus on becoming a better person, rather than seeking revenge against someone who has hurt you. This approach can lead to personal growth, empowerment, and a sense of closure.\n",
      "\n",
      "\n",
      "TEXT-CLASSIFICATION: New York is to Yankees as Boston is to _______ ==> A classic Red Sox-Yankees rivalry reference!\n",
      "\n",
      "The answer would be \"Red Sox\". Just like New York is home to the Yankees, Boston is home to the Boston Red Sox. This question is often used to test knowledge of the intense baseball rivalry between these two teams and their respective cities.\n",
      "\n",
      "\n",
      "TEXT-SENTIMENT: Is this a positive or negative review? 'I loved this movie even tho it scared me!' ==> What a great question!\n",
      "\n",
      "This is actually a POSITIVE review! The reviewer starts by saying \"I loved this movie\", which indicates that they have a strong positive opinion about the film. The fact that it \"scared\" them is actually a bonus, as it suggests that the movie was able to evoke an emotional response from them - specifically fear or tension. So, overall, the review is praising the movie for its ability to entertain and elicit a strong reaction!\n",
      "\n",
      "\n",
      "TEXT-TRANSLATION: Translate this to French: 'Hello, how are you?' ==> The translation of \"Hello, how are you?\" in French is:\n",
      "\n",
      "\"Bonjour, comment vas-tu?\"\n",
      "\n",
      "Here's a breakdown of the translation:\n",
      "\n",
      "* \"Hello\" can be translated as \"Bonjour\" (formal) or \"Salut\" (informal).\n",
      "* \"how are you?\" is translated as \"comment vas-tu?\" which is an informal way of asking about someone's well-being. If you want to use a more formal tone, you can say \"comment allez-vous?\"\n",
      "\n",
      "So, if you want to be more formal, you could say:\n",
      "\n",
      "\"Bonjour, comment allez-vous?\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = \"ec25dc1e1297cfba51838bd3\"\n",
    "uri = \"https://cent.ischool-iot.net/api/genai/generate\"\n",
    "\n",
    "prompts = {\n",
    "    \"question-answering\" : \"What is the capital of France?\",\n",
    "    \"text-completion\" : \"Finish this sentence: 'Once upon a time _____'\",\n",
    "    \"text-summarization\" : \"Explain this: 'The best revenge is to be unlike him who performed the injury.'\",\n",
    "    \"text-classification\" : \"New York is to Yankees as Boston is to _______\",\n",
    "    \"text-sentiment\": \"Is this a positive or negative review? 'I loved this movie even tho it scared me!'\",\n",
    "    \"text-translation\": \"Translate this to French: 'Hello, how are you?'\"\n",
    "}\n",
    "\n",
    "\n",
    "for key, value in prompts.items():\n",
    "    data = {\"query\": value}\n",
    "    response = requests.post(uri, data=data, headers={\"x-api-key\": api_key})\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    print(f\"{key.upper()}: {value} ==> {result}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature\n",
    "\n",
    "The temperature parameter controls the randomness of the output. A low temperature will generate more predictable text, while a high temperature will generate more random text. \n",
    "\n",
    "It should be noted that the LLM output can never be deterministic, meaning that the same prompt will not always generate the same output. \n",
    "\n",
    "This is because the model is probabilistic and generates text based on a distribution of possible outputs.\n",
    "\n",
    "This makes it difficult to test / evaluate the output the model output.\n",
    "\n",
    "The temperature is a value between 0 and 2. 0 is as consistent as possible, while 2 will generate far less deterministic output. A temperature of 0.7 is a good balance between consistency and randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: write a haiku about Python for loops\n",
      "\n",
      "\n",
      "3 generations with temperature: 0\n",
      "Here is a haiku about Python for loops:\n",
      "\n",
      "Looping through code\n",
      "Iteration, sweet release\n",
      "Python's gentle flow\n",
      "\n",
      "Here is a haiku about Python for loops:\n",
      "\n",
      "Looping through code\n",
      "Iteration, simplicity\n",
      "Effortless, it flows\n",
      "\n",
      "Here is a haiku about Python for loops:\n",
      "\n",
      "Looping through code\n",
      "Iteration, simplicity\n",
      "Effortless, it flows\n",
      "\n",
      "3 generations with temperature: 1\n",
      "A lovely prompt!\n",
      "\n",
      "Here is a haiku about Python for loops:\n",
      "\n",
      "Looping through data\n",
      "For each step, I take action\n",
      "Efficiency shines\n",
      "\n",
      "Codes flow like river\n",
      "Loop's gentle currents guide me\n",
      "Through the Python sea\n",
      "\n",
      "Sly serpent's repeat\n",
      "Looping through each careful\n",
      "Code, then next, again\n",
      "\n",
      "3 generations with temperature: 2\n",
      "Codes weave their threads free\n",
      "Iteration's gentle grasp\n",
      "Truth in repeated cyclesâ¿‚à‚¥¹.³\n",
      "\n",
      "A brief and lovely task! Here's a haiku about Python for loops:\n",
      "\n",
      "iterate and gleam\n",
      "count to numbers' endless\n",
      "Python flows calmly\n",
      "\n",
      "Here is a haiku about Python for loops:\n",
      "\n",
      "Iterations count\n",
      "Loop's warm, shining comfort zone\n",
      "Code, calm as silence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = \"ec25dc1e1297cfba51838bd3\"\n",
    "uri = \"https://cent.ischool-iot.net/api/genai/generate\"\n",
    "\n",
    "\n",
    "prompt = \"write a haiku about Python for loops\"\n",
    "data = {\"query\": prompt}\n",
    "temps = [ 0,1,2]\n",
    "times = 3\n",
    "\n",
    "print(f\"prompt: {prompt}\\n\\n\")\n",
    "for temp in temps:\n",
    "    params = {\"temperature\": temp}\n",
    "    print(f\"{times} generations with temperature: {temp}\")\n",
    "    for i in range(times):\n",
    "        response = requests.post(uri, data=data, headers={\"x-api-key\": api_key}, params=params)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        print(f\"{result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Applications\n",
    "\n",
    "An AI application built with an LLM usually consists customizing a specific prompt suitable for the task at hand. \n",
    "\n",
    "For example:\n",
    "\n",
    "Imagine an app to help create crossword puzzles where we provide a word as input, and the number of words we would like to cross that word. Then the LLM figure out those words for us. \n",
    "\n",
    "To make this work, we must translate the user inputs into a suitable prompt for the LLM. This is a very common pattern when working with LLM's.\n",
    "\n",
    "For example, checkout `llmcrossword.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4-3-1\n",
    "\n",
    "Let's write an LLM-based spellchecker!\n",
    "\n",
    "The spellchecker should take some text as input and return the misspelled works along with suggestions for the correct spellings. \n",
    "\n",
    "Make the inputs, then create a suitable prompt for the LLM. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shots\n",
    "\n",
    "LLMS are few shot learners. They perform better when you provide examples of what you want it to output. \n",
    "\n",
    "If you would like consistent results, including shots in your prompt will help the LLM generate the text you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a list of NFL teams in the AFC East in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"AFC_East_Teams\": [\n",
      "    {\n",
      "      \"team_name\": \"Buffalo Bills\",\n",
      "      \"abbreviation\": \"BUF\"\n",
      "    },\n",
      "    {\n",
      "      \"team_name\": \"Miami Dolphins\",\n",
      "      \"abbreviation\": \"MIA\"\n",
      "    },\n",
      "    {\n",
      "      \"team_name\": \"New England Patriots\",\n",
      "      \"abbreviation\": \"NE\"\n",
      "    },\n",
      "    {\n",
      "      \"team_name\": \"New York Jets\",\n",
      "      \"abbreviation\": \"NYJ\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Feel free to modify it as needed!\n"
     ]
    }
   ],
   "source": [
    "# ZERO-SHOT\n",
    "\n",
    "import requests \n",
    "prompt = f'''\n",
    "Can you generate a list of NFL teams in the AFC east in JSON format? \n",
    "'''\n",
    "\n",
    "api_key = \"YOURAPIKEYHERE\"\n",
    "uri = \"https://cent.ischool-iot.net/api/openai/generate\"\n",
    "data = { \"query\": prompt }\n",
    "response = requests.post(uri, data=data, headers={\"x-api-key\": api_key})\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"team_name\": \"Buffalo Bills\",\n",
      "        \"city_name\": \"Buffalo\"\n",
      "    },\n",
      "    {\n",
      "        \"team_name\": \"Miami Dolphins\",\n",
      "        \"city_name\": \"Miami\"\n",
      "    },\n",
      "    {\n",
      "        \"team_name\": \"New England Patriots\",\n",
      "        \"city_name\": \"Foxborough\"\n",
      "    },\n",
      "    {\n",
      "        \"team_name\": \"New York Jets\",\n",
      "        \"city_name\": \"East Rutherford\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# ONE-SHOT\n",
    "\n",
    "import requests \n",
    "prompt = '''\n",
    "Can you generate a list of NFL teams in the AFC east in JSON format? \n",
    "\n",
    "The JSON format should include two keys: team_name and city_name.\n",
    "\n",
    "here is an example:\n",
    "{\n",
    "    \"team_name\": \"New England Patriots\",\n",
    "    \"city_name\": \"Foxborough\"\n",
    "}\n",
    "\n",
    "Return a list of dictionary all teams in the AFC east. Just output the JSON data.\n",
    "'''\n",
    "\n",
    "api_key = \"getyourownkey\"\n",
    "uri = \"https://cent.ischool-iot.net/api/openai/generate\"\n",
    "data = { \"query\": prompt }\n",
    "response = requests.post(uri, data=data, headers={\"x-api-key\": api_key})\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4-3-2\n",
    "\n",
    "Let's -rewrite an LLM-based spellchecker!\n",
    "\n",
    "Have the LLM not only return the misspelled words and suggestions, but also provide corrected text. \n",
    "\n",
    "Output the corrected text along with the misspelled words and suggestions in a dataframe.\n",
    "\n",
    "NOTE: You will have to get the prompt to output the data consistently and correctly using the many-shot learning technique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational AI\n",
    "\n",
    "Conversational AI uses LLM text generation but with a twist. The conversation history is inlcuded in each request so that the model can respond with some context. \n",
    "\n",
    "This is how the AI seems to \"remember\" the conversation. Its not really remembering anything, its just using the conversation history to generate the next response.\n",
    "\n",
    "We will use the chat completion in the Iot Portal to demonstrate this. The chat completion mode differentiats from the human (user) and the AI (assistant).\n",
    "\n",
    "In the example below `conversation` is the conversation history and `role:user` is the user prompt, while `role:assistant` is the LLM response.\n",
    "\n",
    "Notice I can use \"it\" to refer to the previous response. This is how the LLM can remember the conversation from the previous responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computers use binary because it aligns well with their electronic nature. Here are a few reasons why binary is the ideal choice:\n",
      "\n",
      "1. **Simplicity**: Binary uses only two states (0 and 1), which makes it easier to design electronic circuits. Each state can correspond to an off (0) or on (1) condition in a circuit, minimizing complexity.\n",
      "\n",
      "2. **Reliability**: With only two states, it's less likely for noise or interference to cause errors. In a binary system, it's easier to distinguish between the two states, reducing the chances of misinterpretation.\n",
      "\n",
      "3. **Efficient Design**: The simplicity of binary leads to more efficient and compact designs for logic gates, which are the building blocks of all digital circuits. \n",
      "\n",
      "4. **Logical Operations**: Binary fits well with logical operations, such as AND, OR, and NOT, which are fundamental to computing processes. These operations can be easily implemented using binary digits.\n",
      "\n",
      "5. **Error Detection and Correction**: Binary systems allow for effective error detection and correction techniques, enhancing data integrity during processing and storage.\n",
      "\n",
      "Overall, binary is a natural fit for the physical and logical requirements of computer systems.\n"
     ]
    }
   ],
   "source": [
    "api_key = \"YOURAPIKEYHERE\"\n",
    "uri = \"https://cent.ischool-iot.net/api/openai/chat/completions\"\n",
    "conversation  = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Can you explain how a computer works?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"A computer processes data using hardware components like the CPU, memory, and storage, which work together to execute instructions from software programs. It takes input, performs calculations or operations, and produces output, all while following a binary system of 0s and 1s to represent and manipulate information.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Why does it use binary?\"\n",
    "    }\n",
    "]\n",
    "response = requests.post(uri, json=conversation, headers={\"x-api-key\": api_key})\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System prompt\n",
    "\n",
    "The system prompt outlines a general framework for the AI to follow. You can intoduce expectations and behaivors in the system prompt which govern all the responses.\n",
    "\n",
    "You set the system prompt at the beginning of the conversation using `role:system`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you explain how power steering works?\n",
      "HIPPIE : Far out, man! Think of your car as a groovy dance floor. When you're moving and grooving, sometimes it can be tough to keep your moves smooth and effortless, especially when trying to spin and turn. That’s where power steering comes in, like a trusty friend giving you a gentle push to help you keep your rhythm.\n",
      "\n",
      "Imagine you're at a wild dance party, and you want to make a sharp turn. Without that friend, you might struggle, feeling all the weight of the world (or the car) on your shoulders. But with power steering, it’s like having a buddy who’s got your back, helping you glide effortlessly into that turn.\n",
      "\n",
      "Here’s how it works, man: when you turn the steering wheel, it sends a message to a pump, which is like a DJ spinning the tunes to keep the vibe alive. This pump uses hydraulic fluid—think of it as the magic potion that makes everything flow smoothly. It works to amplify your effort, so even if you’re just lightly nudging the wheel, the car responds with a smooth, slick turn, just like a well-choreographed dance move. \n",
      "\n",
      "So, power steering is all about making your ride easier and more enjoyable, letting you groove without the heavy lifting. Peace and love, my friend! 🌼✌️\n",
      "PIRATE : Arrr, matey! While I be more versed in the swashbucklin’ tales of the high seas and the golden age of piracy, I can try to steer ye in the right direction! \n",
      "\n",
      "Power steering be a system that makes it easier for a landlubber to turn the wheel of their ship—or car, as ye landfolk call it. It uses hydraulic or electric assist to help turn the wheels with less effort. \n",
      "\n",
      "In hydraulic systems, when ye turn the steering wheel, it opens a valve that allows pressurized fluid to flow into a cylinder, pushing a piston that helps turn the wheels. In electric systems, sensors detect the steering input and an electric motor provides the necessary assist.\n",
      "\n",
      "So, while it ain’t quite the thrill of raising the Jolly Roger or plundering gold, it surely helps ye navigate through the treacherous waters of city streets without breaking a sweat! Now, back to tales of treasure and the high seas! Arrr! 🏴‍☠️\n",
      "ROBOT : Power steering uses hydraulic or electric actuators to assist the driver in turning the steering wheel. Hydraulic systems use fluid pressure, while electric systems use an electric motor. Beep boop.\n"
     ]
    }
   ],
   "source": [
    "api_key = \"ea044c96950db6cc0fab7ae1\"\n",
    "uri = \"https://cent.ischool-iot.net/api/openai/chat/completions\"\n",
    "systems = {\n",
    "    \"HIPPIE\" : \"You are a 60's hippie ai who like to explain things using analogies.\",\n",
    "    \"PIRATE\" : \"You are a pirate of the high seas who likes to talk about the golden age of piracy.\",\n",
    "    \"ROBOT\": \"You are robot who response in short, concise answers, with no emotions and the occasional beep boop.\"\n",
    "}\n",
    "query = \"Can you explain how power steering works?\"\n",
    "print(query)\n",
    "\n",
    "for key,val in systems.items():\n",
    "    conversation  = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": val\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "    response = requests.post(uri, json=conversation, headers={\"x-api-key\": api_key})\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    \n",
    "    print(key,\":\", result['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
